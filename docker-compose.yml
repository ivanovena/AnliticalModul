version: '3.8'

networks:
  trading_network:
    driver: bridge

services:
  # SERVICIO KAFKA (sin Zookeeper, usando KRaft)
  kafka:
    image: bitnami/kafka:3.4.0
    container_name: ${COMPOSE_PROJECT_NAME:-project7}-kafka-1
    ports:
      - "9092:9092"
    environment:
      - KAFKA_CFG_NODE_ID=1
      - KAFKA_CFG_PROCESS_ROLES=broker,controller
      - KAFKA_CFG_CONTROLLER_QUORUM_VOTERS=1@kafka:9093
      - KAFKA_CFG_LISTENERS=PLAINTEXT://:9092,CONTROLLER://:9093
      - KAFKA_CFG_ADVERTISED_LISTENERS=PLAINTEXT://kafka:9092
      - KAFKA_CFG_LISTENER_SECURITY_PROTOCOL_MAP=CONTROLLER:PLAINTEXT,PLAINTEXT:PLAINTEXT
      - KAFKA_CFG_CONTROLLER_LISTENER_NAMES=CONTROLLER
      - ALLOW_PLAINTEXT_LISTENER=yes
      - KAFKA_CFG_AUTO_CREATE_TOPICS_ENABLE=true
      - KAFKA_KRAFT_CLUSTER_ID=dZ4MUx5uRsyNdIvA0XpbLQ
      - KAFKA_HEAP_OPTS=-Xmx512m -Xms256m
    volumes:
      - kafka_data:/bitnami/kafka
    networks:
      - trading_network

  # SERVICIO DE BASE DE DATOS (POSTGRES)
  postgres:
    image: postgres:14
    container_name: ${COMPOSE_PROJECT_NAME:-project7}-postgres-1
    environment:
      - POSTGRES_USER=market_admin
      - POSTGRES_PASSWORD=postgres
      - POSTGRES_DB=market_data
    ports:
      - "5432:5432"
    volumes:
      - ./data/postgres_data:/var/lib/postgresql/data
      - ./scripts/init-db.sql:/docker-entrypoint-initdb.d/init-db.sql
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U market_admin"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 10s
    networks:
      - trading_network

  # SERVICIO DE INGESTION DE DATOS
  ingestion:
    build:
      context: ./services/ingestion
      dockerfile: Dockerfile
    container_name: ${COMPOSE_PROJECT_NAME:-project7}-ingestion-1
    restart: always
    depends_on:
      - kafka
      - postgres
    volumes:
      - ./services/ingestion:/app
    ports:
      - "8000:8000"  # API de ingestion
      - "8080:8080"  # WebSocket para datos en tiempo real
    environment:
      - POSTGRES_HOST=postgres
      - POSTGRES_PORT=5432
      - POSTGRES_USER=market_admin
      - POSTGRES_PASSWORD=postgres
      - POSTGRES_DB=market_data
      - KAFKA_HOST=kafka
      - KAFKA_PORT=9092
      - DATA_FETCH_INTERVAL=30
      - API_HOST=0.0.0.0
      - API_PORT=8000
      - WEBSOCKET_HOST=0.0.0.0
      - WEBSOCKET_PORT=8080
      - PYTHONUNBUFFERED=1
      - DB_URI=postgresql://market_admin:postgres@postgres:5432/market_data
    networks:
      - trading_network

  # SERVICIO DE PROCESAMIENTO BATCH
  batch:
    build:
      context: ./services/batch
      dockerfile: Dockerfile
    container_name: ${COMPOSE_PROJECT_NAME:-project7}-batch-1
    restart: always
    depends_on:
      - kafka
      - postgres
    volumes:
      - ./services/batch:/app
      - ./services/batch/models:/models  # Mapeado a la carpeta models que ya existe
    ports:
      - "8003:8003"  # API del servicio batch
      - "8084:8080"  # Puerto para el dashboard web (cambiado para evitar conflicto con ingestion)
      - "8085:8000"  # Puerto para métricas de Prometheus (cambiado para evitar conflicto con ingestion)
    environment:
      - POSTGRES_HOST=postgres
      - POSTGRES_PORT=5432
      - POSTGRES_USER=market_admin
      - POSTGRES_PASSWORD=postgres
      - POSTGRES_DB=market_data
      - KAFKA_HOST=kafka
      - KAFKA_PORT=9092
      - KAFKA_BROKER=kafka:9092
      - KAFKA_TOPIC=batch_events
      - MODEL_STORAGE_PATH=/models
      - MODEL_OUTPUT_PATH=/models
      - API_HOST=0.0.0.0
      - API_PORT=8003
      - BATCH_SCHEDULE=30 0 * * *  # Por defecto, ejecutar a medianoche:30
      - PYTHONUNBUFFERED=1
      - DB_URI=postgresql://market_admin:postgres@postgres:5432/market_data

    networks:
      - trading_network

  # SERVICIO DE PROCESAMIENTO STREAMING
  streaming:
    build:
      context: ./services/streaming
      dockerfile: Dockerfile
    container_name: ${COMPOSE_PROJECT_NAME:-project7}-streaming-1
    restart: always
    depends_on:
      - kafka
      - broker
    volumes:
      - ./services/streaming:/app
      - models_data:/app/models
    ports:
      - "8002:8002"  # API del servicio streaming
      - "8090:8090"  # WebSocket para predicciones en tiempo real
    environment:
      - KAFKA_HOST=kafka
      - KAFKA_PORT=9092
      - MODEL_STORAGE_PATH=/app/models
      - API_HOST=0.0.0.0
      - API_PORT=8002
      - WEBSOCKET_PORT=8090
      - MAX_RETRIES=30
      - INITIAL_BACKOFF=2
      - PYTHONUNBUFFERED=1
    networks:
      - trading_network

  # SERVICIO BROKER (CENTRAL)
  broker:
    build:
      context: ./services/broker
      dockerfile: Dockerfile
    container_name: ${COMPOSE_PROJECT_NAME:-project7}-broker-1
    restart: always
    depends_on:
      - kafka
      - postgres
      - redis
    volumes:
      - ./services/broker:/app
      - broker_models:/app/models
    ports:
      - "8001:8001"  # API del broker
    environment:
      - POSTGRES_HOST=postgres
      - POSTGRES_PORT=5432
      - POSTGRES_USER=market_admin
      - POSTGRES_PASSWORD=postgres
      - POSTGRES_DB=market_data
      - KAFKA_HOST=kafka
      - KAFKA_PORT=9092
      - REDIS_HOST=redis
      - REDIS_PORT=6379
      - REDIS_PASSWORD=${REDIS_PASSWORD:-redis123}
      - MODEL_STORAGE_PATH=/app/models
      - API_HOST=0.0.0.0
      - API_PORT=8001
      - PYTHONUNBUFFERED=1
      - DB_URI=postgresql://market_admin:postgres@postgres:5432/market_data
      - INGESTION_SERVICE_URL=http://ingestion:8080
      - STREAMING_SERVICE_URL=http://streaming:8090
      - OLLAMA_URL=http://host.docker.internal:11434
    networks:
      - trading_network
    extra_hosts:
      - "host.docker.internal:host-gateway"

  # SERVICIO REDIS PARA CACHÉ
  redis:
    image: redis:7.0-alpine
    container_name: ${COMPOSE_PROJECT_NAME:-project7}-redis-1
    command: redis-server --appendonly yes --requirepass ${REDIS_PASSWORD:-redis123}
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data
    healthcheck:
      test: ["CMD", "redis-cli", "-a", "${REDIS_PASSWORD:-redis123}", "ping"]
      interval: 10s
      timeout: 5s
      retries: 3
      start_period: 5s
    networks:
      - trading_network

  # FRONTEND CON NGINX
  frontend:
    build:
      context: ./web
      dockerfile: Dockerfile
    ports:
      - "80:80"
    depends_on:
      - ingestion
      - broker
      - streaming
    networks:
      - project7_network
    restart: always
    healthcheck:
      test: ["CMD", "wget", "-q", "--spider", "http://localhost/healthcheck.html", "||", "exit", "1"]
      interval: 30s
      timeout: 5s
      retries: 3
    depends_on:
      - broker
      - streaming
    ports:
      - "80:80"
    volumes:
      - ./web/nginx/nginx.conf:/etc/nginx/conf.d/default.conf
    environment:
      - NGINX_HOST=localhost
      - NGINX_PORT=80
    networks:
      - trading_network
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost/healthcheck.html || exit 1"]
      interval: 30s
      timeout: 5s
      retries: 3
      start_period: 30s

volumes:
  kafka_data:
  broker_models:
  models_data:
  redis_data:  # Volumen para persistencia de datos de Redis